@misc{RN69,
   author = {Badia, Adrià Puigdomènech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Zhaohan Daniel and Blundell, Charles},
   title = {Agent57: Outperforming the Atari Human Benchmark},
   publisher = {PMLR},
   volume = {119},
   pages = {507--517},
   abstract = {Atari games have been a long-standing benchmark in the reinforcement learning (RL) community for the past decade. This benchmark was proposed to test general competency of RL algorithms. Previous work has achieved good average performance by doing outstandingly well on many games of the set, but very poorly in several of the most challenging games. We propose Agent57, the first deep RL agent that outperforms the standard human benchmark on all 57 Atari games. To achieve this result, we train a neural network which parameterizes a family of policies ranging from very exploratory to purely exploitative. We propose an adaptive mechanism to choose which policy to prioritize throughout the training process. Additionally, we utilize a novel parameterization of the architecture that allows for more consistent and stable learning.},
   url = {http://proceedings.mlr.press/v119/badia20a.html},
   year = {2020},
   type = {Conference Paper}
}

@article{RN110,
   author = {Théberge, Antoine and Desrosiers, Christian and Descoteaux, Maxime and Jodoin, Pierre-Marc},
   title = {Track-to-Learn: A general framework for tractography with deep reinforcement learning},
   journal = {Medical Image Analysis},
   volume = {72},
   pages = {102093},
   abstract = {Diffusion MRI tractography is currently the only non-invasive tool able to assess the white-matter structural connectivity of a brain. Since its inception, it has been widely documented that tractography is prone to producing erroneous tracks while missing true positive connections. Recently, supervised learning algorithms have been proposed to learn the tracking procedure implicitly from data, without relying on anatomical priors. However, these methods rely on curated streamlines that are very hard to obtain. To remove the need for such data but still leverage the expressiveness of neural networks, we introduce Track-To-Learn: A general framework to pose tractography as a deep reinforcement learning problem. Deep reinforcement learning is a type of machine learning that does not depend on ground-truth data but rather on the concept of “reward”. We implement and train algorithms to maximize returns from a reward function based on the alignment of streamlines with principal directions extracted from diffusion data. We show competitive results on known data and little loss of performance when generalizing to new, unseen data, compared to prior machine learning-based tractography algorithms. To the best of our knowledge, this is the first successful use of deep reinforcement learning for tractography.},
   keywords = {Tractography Deep learning Reinforcement learning},
   ISSN = {1361-8415},
   DOI = {https://doi.org/10.1016/j.media.2021.102093},
   url = {https://www.sciencedirect.com/science/article/pii/S1361841521001390},
   year = {2021},
   type = {Journal Article}
}

@dataset{ds003900:1.1.1,
  author = {Philippe Poulin and Guillaume Theaud and Pierre-Marc Jodoin and Maxime Descoteaux},
  title = {"TractoInferno: A large-scale, open-source, multi-site database for machine learning dMRI tractography"},
  year = {2022},
  doi = {doi:10.18112/openneuro.ds003900.v1.1.1},
  publisher = {OpenNeuro}
}
